{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ead37f79-16f7-44cd-b6f8-51165979e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8aa324e-ac92-4959-960f-7e898404c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8967a483-6b0a-41dc-a619-1132c553a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "def tokenize_pos(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    return tokens, pos_tags\n",
    "\n",
    "def spacy_summary(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
    "    dependencies = [(token.text, token.dep_) for token in doc]\n",
    "    return {\"entities\": entities, \"noun_chunks\": noun_chunks, \"dependencies\": dependencies}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3198b86a-d629-480f-a8f2-083a41d637c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textstat import flesch_reading_ease, gunning_fog\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def readability_scores(text):\n",
    "    return {\n",
    "        \"flesch\": flesch_reading_ease(text),\n",
    "        \"fog\": gunning_fog(text)\n",
    "    }\n",
    "\n",
    "def get_embeddings(text):\n",
    "    return embedder.encode(text)\n",
    "\n",
    "def build_feature_vector(text):\n",
    "    scores = readability_scores(text)\n",
    "    embedding = get_embeddings(text)\n",
    "    return np.concatenate([list(scores.values()), embedding])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b17e9a30-ef1d-4508-a8a3-f508fcea2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83eb2325-996a-4cdc-a634-0f494b029fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_vector(text):\n",
    "    tokens, pos = tokenize_pos(text)\n",
    "    num_tokens = len(tokens)\n",
    "    unique_tokens = len(set(tokens))\n",
    "    avg_word_len = np.mean([len(t) for t in tokens]) if tokens else 0\n",
    "    noun_count = pos.count(\"NOUN\")\n",
    "    verb_count = pos.count(\"VERB\")\n",
    "\n",
    "    return [\n",
    "        num_tokens,\n",
    "        unique_tokens,\n",
    "        avg_word_len,\n",
    "        noun_count,\n",
    "        verb_count\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03f65110-f182-4507-8664-f5710d5450b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12976, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/training_set_rel3.tsv\", sep='\\t', encoding='ISO-8859-1')\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40c1ed88-85f0-40e1-8dd2-84f2bf513a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    dear local newspaper i think effects computers...\n",
       "1    dear caps1 caps2 i believe that using computer...\n",
       "2    dear caps1 caps2 caps3 more and more people us...\n",
       "3    dear local newspaper caps1 i have found that m...\n",
       "4    dear location1 i know having computers has a p...\n",
       "Name: cleaned_essay, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_essay\"] = df[\"essay\"].apply(clean_text)\n",
    "df[\"cleaned_essay\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c11457d5-7dec-4a67-8b61-67a2046633fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12976/12976 [26:55:44<00:00,  7.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>cleaned_essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dear local newspaper i think effects computers...</td>\n",
       "      <td>341.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
       "      <td>422.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.459716</td>\n",
       "      <td>103.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.524823</td>\n",
       "      <td>75.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater3_trait5  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater3_trait6                                      cleaned_essay  \\\n",
       "0            NaN  dear local newspaper i think effects computers...   \n",
       "1            NaN  dear caps1 caps2 i believe that using computer...   \n",
       "2            NaN  dear caps1 caps2 caps3 more and more people us...   \n",
       "\n",
       "   word_count  sentence_count  type_token_ratio  noun_count  verb_count  \\\n",
       "0       341.0             2.0          0.483871        73.0        49.0   \n",
       "1       422.0             2.0          0.459716       103.0        70.0   \n",
       "2       282.0             2.0          0.524823        75.0        40.0   \n",
       "\n",
       "   adj_count  adv_count  \n",
       "0       21.0       16.0  \n",
       "1       20.0       16.0  \n",
       "2       20.0       11.0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def extract_features(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = [token.text for token in doc if not token.is_punct and not token.is_space]\n",
    "    num_tokens = len(tokens)\n",
    "    num_sentences = len(list(doc.sents))\n",
    "\n",
    "    unique_tokens = set(tokens)\n",
    "    type_token_ratio = len(unique_tokens) / num_tokens if num_tokens > 0 else 0\n",
    "\n",
    "    pos_counts = {\n",
    "        \"noun_count\": sum(1 for token in doc if token.pos_ == \"NOUN\"),\n",
    "        \"verb_count\": sum(1 for token in doc if token.pos_ == \"VERB\"),\n",
    "        \"adj_count\": sum(1 for token in doc if token.pos_ == \"ADJ\"),\n",
    "        \"adv_count\": sum(1 for token in doc if token.pos_ == \"ADV\"),\n",
    "    }\n",
    "\n",
    "    return pd.Series({\n",
    "        \"word_count\": num_tokens,\n",
    "        \"sentence_count\": num_sentences,\n",
    "        \"type_token_ratio\": type_token_ratio,\n",
    "        **pos_counts\n",
    "    })\n",
    "\n",
    "features_df = df[\"cleaned_essay\"].progress_apply(extract_features)\n",
    "df = pd.concat([df, features_df], axis=1)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "524b91b1-f775-439e-a5cd-9360ccbd623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (3.3.1)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.47.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.26.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.3.1\n",
      "    Uninstalling sentence-transformers-3.3.1:\n",
      "      Successfully uninstalled sentence-transformers-3.3.1\n",
      "Successfully installed sentence-transformers-4.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbf00c9f-54de-4c37-af0a-6e75b44b5772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577c0bbd2b8a44ea984aff6a5deec3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "essay_embeddings = model.encode(df[\"cleaned_essay\"].tolist(), show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67667899-31ae-48a1-9917-bd447fcf461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.hstack([essay_embeddings, df[[\n",
    "    \"word_count\", \"sentence_count\", \"type_token_ratio\",\n",
    "    \"noun_count\", \"verb_count\", \"adj_count\", \"adv_count\"\n",
    "]].values])\n",
    "y = df[\"domain1_score\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bcef702-530d-4420-88bc-94754bed5c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from lightgbm) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    " pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f66a111-0d7f-4fed-a435-5de70e90895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 98944\n",
      "[LightGBM] [Info] Number of data points in the train set: 10380, number of used features: 391\n",
      "[LightGBM] [Info] Start training from score 6.832563\n",
      "Validation RMSE: 2.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define and train the model\n",
    "model = LGBMRegressor(\n",
    "    objective='regression',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    n_estimators=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    \n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(f\"Validation RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bea1345-0005-4ead-b26c-4e14ea611099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/DELL/Documents/aes/api/saved_model/essay_scorer.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"C:/Users/DELL/Documents/aes/api/saved_model/essay_scorer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9a55f-cec9-4403-9075-6b2439558c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
